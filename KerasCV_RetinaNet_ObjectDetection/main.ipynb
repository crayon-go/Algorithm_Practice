{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a241497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "import keras_cv\n",
    "from keras_cv import bounding_box\n",
    "import os\n",
    "from luketils import visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcf00bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "cEPOCHS = int(os.getenv(\"EPOCHS\", \"1\"))\n",
    "CHECKPOINT_PATH = os.getenv(\"CHECKPOINT_PATH\", \"checkpoint/\")\n",
    "INFERENCE_CHECKPOINT_PATH = os.getenv(\"INFERENCE_CHECKPOINT_PATH\", CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012b2f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_ds, ds_info = keras_cv.datasets.pascal_voc.load(\n",
    "    split='train', bounding_box_format='xywh', batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bbdf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_info = keras_cv.datasets.pascal_voc.load(\n",
    "    split=\"train\", bounding_box_format=\"xywh\", batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_ids = [\n",
    "    \"Aeroplane\",\n",
    "    \"Bicycle\",\n",
    "    \"Bird\",\n",
    "    \"Boat\",\n",
    "    \"Bottle\",\n",
    "    \"Bus\",\n",
    "    \"Car\",\n",
    "    \"Cat\",\n",
    "    \"Chair\",\n",
    "    \"Cow\",\n",
    "    \"Dining Table\",\n",
    "    \"Dog\",\n",
    "    \"Horse\",\n",
    "    \"Motorbike\",\n",
    "    \"Person\",\n",
    "    \"Potted Plant\",\n",
    "    \"Sheep\",\n",
    "    \"Sofa\",\n",
    "    \"Train\",\n",
    "    \"Tvmonitor\",\n",
    "    \"Total\",\n",
    "]\n",
    "class_mapping = dict(zip(range(len(class_ids)), class_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528018c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_dataset(dataset, bounding_box_format):\n",
    "    example = next(iter(dataset))\n",
    "    images, boxes = example[\"images\"], example[\"bounding_boxes\"]\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        y_true=boxes,\n",
    "        scale=4,\n",
    "        rows=3,\n",
    "        cols=3,\n",
    "        show=True,\n",
    "        thickness=4,\n",
    "        font_scale=1,\n",
    "        class_mapping=class_mapping,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5499f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset(dataset, bounding_box_format=\"xywh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a04e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_dataset_info = keras_cv.datasets.pascal_voc.load(\n",
    "    bounding_box_format=\"xywh\", split=\"train\", batch_size=BATCH_SIZE\n",
    ")\n",
    "val_ds, val_dataset_info = keras_cv.datasets.pascal_voc.load(\n",
    "    bounding_box_format=\"xywh\", split=\"validation\", batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f551d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_flip = keras_cv.layers.RandomFlip(mode=\"horizontal\", bounding_box_format=\"xywh\")\n",
    "rand_augment = keras_cv.layers.RandAugment(\n",
    "    value_range=(0, 255),\n",
    "    augmentations_per_image=2,\n",
    "    # we disable geometric augmentations for object detection tasks\n",
    "    geometric=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104d9669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(inputs):\n",
    "    # In future KerasCV releases, RandAugment will support\n",
    "    # bounding box detection\n",
    "    inputs[\"images\"] = rand_augment(inputs[\"images\"])\n",
    "    inputs = random_flip(inputs)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0d653",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "visualize_dataset(train_ds, bounding_box_format=\"xywh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4ff276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_tuple(inputs):\n",
    "    return inputs[\"images\"], inputs[\"bounding_boxes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c331c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf83eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras_cv.models.RetinaNet(\n",
    "    # 감지할 클래스 의 갯수\n",
    "    classes=20,\n",
    "    # 지원하는 bounding box formats에 대해서 더 자세히 표기 위해 아래 링크를 참조합니다.\n",
    "    # https://keras.io/api/keras_cv/bounding_box/\n",
    "    bounding_box_format=\"xywh\",\n",
    "    # KerasCV는 사전 학습한 모델을 제공합니다\n",
    "    backbone=\"resnet50\",\n",
    "    # 각 모델은 학습한 가중치를 가지고 있습니다\n",
    "    # 이 가중치는 `keras_cv.model` 클래스의 가중치와 일치합니다.\n",
    "    backbone_weights=\"imagenet\",\n",
    "    # include_rescaling는 모델에게 이미지의 픽셀값이 (0, 255)라는 것을 알려주거나\n",
    "    # 이미 0과 255 사이의 값으로 조정했다면 그 값은 (0, 1) 사이라고 알려줍니다.\n",
    "    # 예제의 경우, (0, 255)로 입력값을 사용합니다.\n",
    "    include_rescaling=True,\n",
    "    # 일반적으로 실제 모델을 학습할 때는 이 값은 False로 설정하려고 합니다.\n",
    "    # evaluate_train_time_metrics=True 는 `train_step()`가 TPU와 호환되지 않습니다,\n",
    "    # 또한, 많은 처리량이 필요합니다. 모델 학습 파이프라인을 디버깅할 때, 유용합니다\n",
    "    evaluate_train_time_metrics=False,\n",
    ")\n",
    "# RetinaNet을 파인 튜닝하는 것은 backbone.trainable = False로 간단히 할 수 있습니다.\n",
    "model.backbone.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813ab730",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    keras_cv.metrics.COCOMeanAveragePrecision(\n",
    "        class_ids=range(20),\n",
    "        bounding_box_format=\"xywh\",\n",
    "        name=\"Mean Average Precision\",\n",
    "    ),\n",
    "    keras_cv.metrics.COCORecall(\n",
    "        class_ids=range(20),\n",
    "        bounding_box_format=\"xywh\",\n",
    "        max_detections=100,\n",
    "        name=\"Recall\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafcd2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.SGD(global_clipnorm=10.0)\n",
    "model.compile(\n",
    "    classification_loss=keras_cv.losses.FocalLoss(from_logits=True, reduction=\"none\"),\n",
    "    box_loss=keras_cv.losses.SmoothL1Loss(l1_cutoff=1.0, reduction=\"none\"),\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\n",
    "        keras_cv.metrics.COCOMeanAveragePrecision(\n",
    "            class_ids=range(20),\n",
    "            bounding_box_format=\"xywh\",\n",
    "            name=\"Mean Average Precision\",\n",
    "        ),\n",
    "        keras_cv.metrics.COCORecall(\n",
    "            class_ids=range(20),\n",
    "            bounding_box_format=\"xywh\",\n",
    "            max_detections=100,\n",
    "            name=\"Recall\",\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06ded9",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.TensorBoard(log_dir=\"logs\"),\n",
    "    keras.callbacks.ReduceLROnPlateau(patience=5),\n",
    "    # Uncomment to train your own RetinaNet\n",
    "    keras.callbacks.ModelCheckpoint(CHECKPOINT_PATH, save_weights_only=True),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds.take(20),\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "model.save_weights(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6888cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(INFERENCE_CHECKPOINT_PATH)\n",
    "metrics = model.evaluate(val_ds.take(100), return_dict=True)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52ea42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(model, bounding_box_format):\n",
    "    train_ds, val_dataset_info = keras_cv.datasets.pascal_voc.load(\n",
    "        bounding_box_format=bounding_box_format, split=\"train\", batch_size=BATCH_SIZE\n",
    "    )\n",
    "    train_ds = train_ds.map(dict_to_tuple, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    images, y_true = next(iter(train_ds.take(1)))\n",
    "    y_pred = model.predict(images)\n",
    "    visualization.plot_bounding_box_gallery(\n",
    "        images,\n",
    "        value_range=(0, 255),\n",
    "        bounding_box_format=bounding_box_format,\n",
    "        y_true=y_true,\n",
    "        y_pred=y_pred,\n",
    "        scale=4,\n",
    "        rows=3,\n",
    "        cols=3,\n",
    "        show=True,\n",
    "        thickness=4,\n",
    "        font_scale=1,\n",
    "        class_mapping=class_mapping,\n",
    "    )\n",
    "\n",
    "\n",
    "visualize_detections(model, bounding_box_format=\"xywh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05477e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_decoder = keras_cv.layers.NmsPredictionDecoder(\n",
    "    bounding_box_format=\"xywh\",\n",
    "    anchor_generator=keras_cv.models.RetinaNet.default_anchor_generator(\n",
    "        bounding_box_format=\"xywh\"\n",
    "    ),\n",
    "    suppression_layer=keras_cv.layers.NonMaxSuppression(\n",
    "        iou_threshold=0.75,\n",
    "        bounding_box_format=\"xywh\",\n",
    "        classes=20,\n",
    "        confidence_threshold=0.85,\n",
    "    ),\n",
    ")\n",
    "model.prediction_decoder = prediction_decoder\n",
    "visualize_detections(model, bounding_box_format=\"xywh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e362175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20901a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aba4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd109015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd495e17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackerrank",
   "language": "python",
   "name": "hackerrank"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
